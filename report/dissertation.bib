
@article{yee-king_automatic_nodate,
	title = {Automatic Sound Synthesizer Programming: Techniques and Applications},
	abstract = {The aim of this thesis is to investigate techniques for, and applications of automatic sound synthesizer programming. An automatic sound synthesizer programmer is a system which removes the requirement to explicitly specify parameter settings for a sound synthesis algorithm from the user. Two forms of these systems are discussed in this thesis: tone matching programmers and synthesis space explorers. A tone matching programmer takes at its input a sound synthesis algorithm and a desired target sound. At its output it produces a conﬁguration for the sound synthesis algorithm which causes it to emit a similar sound to the target. The techniques for achieving this that are investigated are genetic algorithms, neural networks, hill climbers and data driven approaches. A synthesis space explorer provides a user with a representation of the space of possible sounds that a synthesizer can produce and allows them to interactively explore this space. The applications of automatic sound synthesizer programming that are investigated include studio tools, an autonomous musical agent and a self-reprogramming drum machine. The research employs several methodologies: the development of novel software frameworks and tools, the examination of existing software at the source code and performance levels and user trials of the tools and software. The main contributions made are: a method for visualisation of sound synthesis space and low dimensional control of sound synthesizers; a general purpose framework for the deployment and testing of sound synthesis and optimisation algorithms in the {SuperCollider} language sclang; a comparison of a variety of optimisation techniques for sound synthesizer programming; an analysis of sound synthesizer error surfaces; a general purpose sound synthesizer programmer compatible with industry standard tools; an automatic improviser which passes a loose equivalent of the Turing test for Jazz musicians, i.e. being half of a man-machine duet which was rated as one of the best sessions of 2009 on the {BBC}’s ’Jazz on 3’ programme.},
	pages = {180},
	author = {Yee-King, Matthew John},
	langid = {english}
}

@article{yee-king_synthbot:_nodate,
	title = {{SYNTHBOT}: {AN} {UNSUPERVISED} {SOFTWARE} {SYNTHESIZER} {PROGRAMMER}},
	abstract = {This work presents a software synthesizer programmer, {SynthBot}, which is able to automatically ﬁnd the settings necessary to produce a sound similar to a given target. As modern synthesizers become more capable and the underlying synthesis architectures more obscure, the task of programming them to produce a desired sound becomes more time consuming and complex. {SynthBot} is presented as an automated solution to this problem. A stochastic search algorithm, in this case a genetic algorithm, is used to ﬁnd the parameters which produce the most similar sound to the target. Similarity is measured by the sum squared error between the Mel Frequency Cepstrum Coefﬁcients ({MFCCs}) of the target and candidate sounds.},
	pages = {4},
	author = {Yee-King, Matthew and Roth, Martin},
	langid = {english}
}

@article{johnson_exploring_nodate,
	title = {Exploring the sound-space of synthesis algorithms using interactive genetic algorithms.},
	abstract = {Exploring the sounds available from a synthesis algorithm is a complicated process, requiring the user either to spend much time gaining heuristic experience with the algorithm or requiring them to have a deep knowledge of the underlying synthesis algorithms. In this paper we describe a computer system which facilitates a more exploratory approach to sound design, allowing the user to work at the level of the sounds themselves. In this system the synthesis parameters are managed by a genetic algorithm, which is directed by the users’ judgements about the sounds in the system. We describe the development of a prototype version of this system, concentrating on an interface to the {FOF} granular synthesis algorithm from {CSound}.},
	pages = {9},
	author = {Johnson, Colin G},
	langid = {english}
}

@article{yee-king_automatic_2018,
	title = {Automatic Programming of {VST} Sound Synthesizers Using Deep Networks and Other Techniques},
	volume = {2},
	issn = {2471-285X},
	doi = {10.1109/TETCI.2017.2783885},
	abstract = {Programming sound synthesizers is a complex and time-consuming task. Automatic synthesizer programming involves finding parameters for sound synthesizers using algorithmic methods. Sound matching is one application of automatic programming, where the aim is to find the parameters for a synthesizer that cause it to emit as close a sound as possible to a target sound. We describe and compare several sound matching techniques that can be used to automatically program the Dexed synthesizer, which is a virtual model of a Yamaha {DX}7. The techniques are a hill climber, a genetic algorithm, and three deep neural networks that have not been applied to the problem before. We define a sound matching task based on six sets of sounds, which we derived from increasingly complex configurations of the Dexed synthesis algorithm. A bidirectional, long short-term memory network with highway layers performed better than any other technique and was able to match sounds closely in 25\% of the test cases. This network was also able to match sounds in near real time, once trained, which provides a significant speed advantage over previously reported techniques that are based on search heuristics. We also describe our open source framework, which makes it possible to repeat our study, and to adapt it to different synthesizers and algorithmic programming techniques.},
	pages = {150--159},
	number = {2},
	journaltitle = {{IEEE} Transactions on Emerging Topics in Computational Intelligence},
	author = {Yee-King, M. J. and Fedden, L. and d'Inverno, M.},
	date = {2018-04},
	keywords = {algorithmic methods, algorithmic programming, artificial neural networks, automatic programming, automatic synthesizer programming, Computer generated music, deep networks, deep neural networks, Dexed synthesis algorithm, Dexed synthesizer, electronic music, Feature extraction, Frequency modulation, frequency modulation ({FM}), genetic algorithms, Genetic algorithms, genetic algorithms ({GA}), music, neural nets, programming, Programming profession, short-term memory network, signal synthesis, sound matching, sound matching task, Synthesizers, target sound, Task analysis, {VST} sound synthesizers}
}

@book{noauthor_oneohtrix_2016,
	title = {Oneohtrix Point Never on the process behind his latest leap into the unknown, Garden of Delete},
	url = {https://www.musicradar.com/news/tech/oneohtrix-point-never-on-the-process-behind-his-latest-leap-into-the-unknown-garden-of-delete-633280},
	urldate = {2018-11-18},
	date = {2016-02}
}

@book{herbert_manifesto_2011,
	title = {manifesto {\textbackslash}textbar Matthew Herbert},
	url = {https://matthewherbert.com/about-contact/manifesto/},
	author = {Herbert, Matthew},
	urldate = {2018-11-18},
	date = {2011},
	langid = {american}
}

@book{mcdonald_neural_2017,
	title = {Neural Nets for Generating Music},
	url = {https://medium.com/artists-and-machine-intelligence/neural-nets-for-generating-music-f46dffac21c0},
	abstract = {Algorithmic music composition has developed a lot in the last few years, but the idea has a long history. In some sense, the first…},
	author = {{McDonald}, Kyle},
	urldate = {2018-11-18},
	date = {2017-08}
}

@article{tatar_automatic_2016,
	title = {Automatic Synthesizer Preset Generation with \textit{{PresetGen}}},
	volume = {45},
	issn = {0929-8215, 1744-5027},
	url = {http://www.tandfonline.com/doi/full/10.1080/09298215.2016.1175481},
	doi = {10.1080/09298215.2016.1175481},
	abstract = {We refer the task of ﬁnding preset(s) (i.e. set(s) of synthesizer parameters) that approximates a target sound best, as the preset generation problem. {PresetGen} addresses this problem regarding the real world synthesizer, {OP}-1. The {OP}-1 consists of several synthesis blocks, and it is not fully deterministic. We propose and evaluate a solution to preset generation using a multi-objective Non-dominated Sorting-Genetic-{AlgorithmII}. {PresetGen} handles the full problem complexity and returns a small set of presets that approximate the target sound best by covering the Pareto front of this multi-objective optimization problem. Moreover, we present an empirical evaluation experiment that compares the performance of three human sound designers to that of {PresetGen}. The results show that {PresetGen} is human-competitive.},
	pages = {124--144},
	number = {2},
	journaltitle = {Journal of New Music Research},
	author = {Tatar, Kıvanç and Macret, Matthieu and Pasquier, Philippe},
	urldate = {2018-11-19},
	date = {2016-04},
	langid = {english}
}

@book{noauthor_granulator_nodate,
	title = {Granulator by Robert Henke},
	url = {http://roberthenke.com/technology/granulator.html},
	urldate = {2018-11-19}
}

@article{gerhard_pitch_nodate,
	title = {Pitch Extraction and Fundamental Frequency: History and Current Techniques},
	abstract = {Pitch extraction (also called fundamental frequency estimation) has been a popular topic in many ﬁelds of research since the age of computers. Yet in the course of some 50 years of study, current techniques are still not to a desired level of accuracy and robustness. When presented with a single clean pitched signal, most techniques do well, but when the signal is noisy, or when there are multiple pitch streams, many current pitch algorithms still fail to perform well. This report presents a discussion of the history of pitch detection techniques, as well as a survey of the current state of the art in pitch detection technology.},
	pages = {23},
	author = {Gerhard, David},
	langid = {english}
}

@book{muller_information_2007,
	title = {Information Retrieval for Music and Motion},
	isbn = {978-3-540-74048-3},
	abstract = {A general scenario that has attracted a lot of attention for multimedia information retrieval is based on the query-by-example paradigm: retrieve all documents from a database containing parts or aspects similar to a given data fragment. However, multimedia objects, even though they are similar from a structural or semantic viewpoint, often reveal significant spatial or temporal differences. This makes content-based multimedia retrieval a challenging research field with many unsolved problems. Meinard Müller details concepts and algorithms for robust and efficient information retrieval by means of two different types of multimedia data: waveform-based music data and human motion data. In Part I, he discusses in depth several approaches in music information retrieval, in particular general strategies as well as efficient algorithms for music synchronization, audio matching, and audio structure analysis. He also shows how the analysis results can be used in an advanced audio player to facilitate additional retrieval and browsing functionality. In Part {II}, he introduces a general and unified framework for motion analysis, retrieval, and classification, highlighting the design of suitable features, the notion of similarity used to compare data streams, and data organization. The detailed chapters at the beginning of each part give consideration to the interdisciplinary character of this field, covering information science, digital signal processing, audio engineering, musicology, and computer graphics. This first monograph specializing in music and motion retrieval appeals to a wide audience, from students at the graduate level and lecturers to scientists working in the above mentioned fields in academia or industry. Lecturers and students will benefit from the didactic style, and each unit is suitable for stand-alone use in specialized graduate courses. Researchers will be interested in the detailed description of original research results and their application in real-world browsing and retrieval scenarios.},
	publisher = {Springer Science \& Business Media},
	author = {Müller, Meinard},
	date = {2007-09},
	langid = {english},
	keywords = {Computers / Computer Graphics, Computers / Computer Science, Computers / Data Processing, Computers / Databases / General, Computers / Desktop Applications / Design \& Graphics, Computers / General, Computers / Information Technology, Computers / Interactive \& Multimedia, Computers / System Administration / Storage \& Retrieval}
}

@book{noauthor_librosa_nodate,
	title = {Librosa},
	url = {https://librosa.github.io/},
	urldate = {2019-05-03}
}

@book{noauthor_homepage_nodate,
	title = {Homepage — Essentia 2.1-beta5-dev documentation},
	url = {https://essentia.upf.edu/documentation/},
	urldate = {2019-05-03}
}

@book{noauthor_audacity_nodate,
	title = {Audacity ® {\textbackslash}textbar Free, open source, cross-platform audio software for multi-track recording and editing.},
	url = {https://www.audacityteam.org/},
	urldate = {2019-05-03},
	langid = {american}
}

@article{horner_machine_1993,
	title = {Machine Tongues {XVI}: Genetic Algorithms and Their Application to {FM} Matching Synthesis},
	volume = {17},
	issn = {01489267},
	url = {https://www.jstor.org/stable/3680541?origin=crossref},
	doi = {10.2307/3680541},
	shorttitle = {Machine Tongues {XVI}},
	pages = {17},
	number = {4},
	journaltitle = {Computer Music Journal},
	author = {Horner, Andrew and Beauchamp, James and Haken, Lippold},
	urldate = {2019-05-03},
	date = {1993},
	langid = {english}
}

@article{heise_automated_2009,
	title = {Automated Cloning of Recorded Sounds by Software Synthesizers},
	abstract = {Any audio recording can be turned into a digital musical instrument by feeding it into an audio sampler. However, it is difficult to edit such a sound in musical terms or even to control it in real time with musical expression. This does not change much if a more sophisticated resynthesis method is applied. Many electronic musicians appreciate the direct and clear access to sound parameters a traditional analog synthesizer offers. Can one automatically generate a synthesizer setting that approximates a given audio recording and thus clone a given sound to be controlled with the standard functions of the particular synthesizer employed? Even though this problem seems highly complex, we demonstrate that its solution becomes feasible with today’s computer systems. We compare sounds on the basis of acoustic features known from Music Information Retrieval and apply a specialized optimization strategy to adjust the settings of {VST} instruments, which is sped up using multi-core processors and networked computers.},
	pages = {8},
	journaltitle = {New York},
	author = {Heise, Sebastian and Hlatky, Michael and Loviscach, Jörn},
	date = {2009},
	langid = {english}
}

@inproceedings{eronen_comparison_2001,
	location = {New Platz, {NY}, {USA}},
	title = {Comparison of features for musical instrument recognition},
	isbn = {978-0-7803-7126-2},
	url = {http://ieeexplore.ieee.org/document/969532/},
	doi = {10.1109/ASPAA.2001.969532},
	abstract = {Several features were compared with regard to recognition performance in a musical instrument recognition system. Both melfrequency and linear prediction cepstral and delta cepstral coefﬁcients were calculated. Linear prediction analysis was carried out both on a uniform and a warped frequency scale, and reﬂection coefﬁcients were also used as features. The performance of earlier described features relating to the temporal development, modulation properties, brightness, and spectral synchronity of sounds was also analysed. The data base consisted of 5286 acoustic and synthetic solo tones from 29 different Western orchestral instruments, out of which 16 instruments were included in the test set. The best performance for solo tone recognition, 35\% for individual instruments and 77\% for families, was obtained with a feature set consisting of two sets of mel-frequency cepstral coefﬁcients and a subset of the other analysed features. The confusions made by the system were analysed and compared to results reported in a human perception experiment.},
	pages = {19--22},
	booktitle = {Proceedings of the 2001 {IEEE} Workshop on the Applications of Signal Processing to Audio and Acoustics (Cat. No.01TH8575)},
	publisher = {{IEEE}},
	author = {Eronen, A.},
	urldate = {2019-05-03},
	date = {2001},
	langid = {english}
}

@article{terasawa_center_2005,
	title = {Center for Computer Research in Music and Acoustics ({CCRMA}) Department of Music, Stanford University Stanford, California},
	abstract = {This paper describes a perceptual space for timbre, deﬁnes an objective metric that takes into account perceptual orthogonality, and measures the quality of timbre interpolation applicable to perceptually valid timbral soniﬁcation. We discuss two timbre representations and measure perceptual judgment. We determined that a timbre space based on Mel-frequency cepstral coefﬁcients ({MFCC}) is a good model for perceptual timbre space.},
	pages = {8},
	author = {Terasawa, Hiroko and Slaney, Malcolm and Berger, Jonathan},
	date = {2005},
	langid = {english}
}

@article{mitchell_frequency_2005,
	title = {Frequency Modulation Tone Matching Using a Fuzzy Clustering Evolution Strategy},
	abstract = {Frequency Modulation parameter estimation has provided a continual challenge to researchers since its ﬁrst application to audio synthesis over thirty years ago. Recent research has made use of basic evolutionary optimisation algorithms to evolve sounds produced by non-standard Frequency Modulation arrangements. In contrast, this paper utilises recent advances in multi-modal evolutionary optimisation to perform dynamicsound matching with traditional arrangements. In doing so, a technique is developed that is not synthesiser dependent, and provides the potential for alternative methods of synthesis control.},
	pages = {12},
	author = {Mitchell, Thomas J and Sullivan, J Charles W},
	date = {2005},
	langid = {english},
	file = {Mitchell and Sullivan - 2005 - Frequency Modulation Tone Matching Using a Fuzzy C.pdf:/home/bakunowski/Zotero/storage/29ENIH82/Mitchell and Sullivan - 2005 - Frequency Modulation Tone Matching Using a Fuzzy C.pdf:application/pdf}
}

@article{yee-king_comparison_2011,
	title = {A Comparison of Parametric Optimisation Techniques for Musical Instrument Tone Matching},
	abstract = {Parametric optimisation techniques are compared in their abilities to elicit parameter settings for sound synthesis algorithms which cause them to emit sounds as similar as possible to target sounds. A hill climber, a genetic algorithm, a neural net and a data driven approach are compared. The error metric used is the Euclidean distance in {MFCC} feature space. This metric is justiﬁed on the basis of its success in previous work. The genetic algorithm oﬀers the best results with the {FM} and subtractive test synthesizers but the hill climber and data driven approach also oﬀer strong performance. The concept of sound synthesis error surfaces, allowing the detailed description of sound synthesis space, is introduced. The error surface for an {FM} synthesizer is described and suggestions are made as to the resolution required to eﬀectively represent these surfaces. This information is used to inform future plans for algorithm improvements.},
	pages = {9},
	author = {Yee-King, Matthew and Roth, Martin},
	date = {2011},
	langid = {english},
	file = {Yee-King and Roth - 2011 - A Comparison of Parametric Optimisation Techniques.pdf:/home/bakunowski/Zotero/storage/H2SARUPZ/Yee-King and Roth - 2011 - A Comparison of Parametric Optimisation Techniques.pdf:application/pdf}
}