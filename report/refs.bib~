
@article{yee-king_automatic_nodate,
	title = {Automatic {Sound} {Synthesizer} {Programming}: {Techniques} and {Applications}},
	abstract = {The aim of this thesis is to investigate techniques for, and applications of automatic sound synthesizer programming. An automatic sound synthesizer programmer is a system which removes the requirement to explicitly specify parameter settings for a sound synthesis algorithm from the user. Two forms of these systems are discussed in this thesis: tone matching programmers and synthesis space explorers. A tone matching programmer takes at its input a sound synthesis algorithm and a desired target sound. At its output it produces a conﬁguration for the sound synthesis algorithm which causes it to emit a similar sound to the target. The techniques for achieving this that are investigated are genetic algorithms, neural networks, hill climbers and data driven approaches. A synthesis space explorer provides a user with a representation of the space of possible sounds that a synthesizer can produce and allows them to interactively explore this space. The applications of automatic sound synthesizer programming that are investigated include studio tools, an autonomous musical agent and a self-reprogramming drum machine. The research employs several methodologies: the development of novel software frameworks and tools, the examination of existing software at the source code and performance levels and user trials of the tools and software. The main contributions made are: a method for visualisation of sound synthesis space and low dimensional control of sound synthesizers; a general purpose framework for the deployment and testing of sound synthesis and optimisation algorithms in the SuperCollider language sclang; a comparison of a variety of optimisation techniques for sound synthesizer programming; an analysis of sound synthesizer error surfaces; a general purpose sound synthesizer programmer compatible with industry standard tools; an automatic improviser which passes a loose equivalent of the Turing test for Jazz musicians, i.e. being half of a man-machine duet which was rated as one of the best sessions of 2009 on the BBC’s ’Jazz on 3’ programme.},
	language = {en},
	author = {Yee-King, Matthew John},
	pages = {180},
	file = {Yee-King - Automatic Sound Synthesizer Programming Technique.pdf:/Users/bakunowski/Zotero/storage/LLWFLRMT/Yee-King - Automatic Sound Synthesizer Programming Technique.pdf:application/pdf}
}

@article{yee-king_synthbot:_nodate,
	title = {{SYNTHBOT}: {AN} {UNSUPERVISED} {SOFTWARE} {SYNTHESIZER} {PROGRAMMER}},
	abstract = {This work presents a software synthesizer programmer, SynthBot, which is able to automatically ﬁnd the settings necessary to produce a sound similar to a given target. As modern synthesizers become more capable and the underlying synthesis architectures more obscure, the task of programming them to produce a desired sound becomes more time consuming and complex. SynthBot is presented as an automated solution to this problem. A stochastic search algorithm, in this case a genetic algorithm, is used to ﬁnd the parameters which produce the most similar sound to the target. Similarity is measured by the sum squared error between the Mel Frequency Cepstrum Coefﬁcients (MFCCs) of the target and candidate sounds.},
	language = {en},
	author = {Yee-King, Matthew and Roth, Martin},
	pages = {4},
	file = {Yee-King and Roth - SYNTHBOT AN UNSUPERVISED SOFTWARE SYNTHESIZER PRO.pdf:/Users/bakunowski/Zotero/storage/NSPM7NLY/Yee-King and Roth - SYNTHBOT AN UNSUPERVISED SOFTWARE SYNTHESIZER PRO.pdf:application/pdf}
}

@article{johnson_exploring_nodate,
	title = {Exploring the sound-space of synthesis algorithms using interactive genetic algorithms.},
	abstract = {Exploring the sounds available from a synthesis algorithm is a complicated process, requiring the user either to spend much time gaining heuristic experience with the algorithm or requiring them to have a deep knowledge of the underlying synthesis algorithms. In this paper we describe a computer system which facilitates a more exploratory approach to sound design, allowing the user to work at the level of the sounds themselves. In this system the synthesis parameters are managed by a genetic algorithm, which is directed by the users’ judgements about the sounds in the system. We describe the development of a prototype version of this system, concentrating on an interface to the FOF granular synthesis algorithm from CSound.},
	language = {en},
	author = {Johnson, Colin G},
	pages = {9}
}

@article{yee-king_automatic_2018,
	title = {Automatic {Programming} of {VST} {Sound} {Synthesizers} {Using} {Deep} {Networks} and {Other} {Techniques}},
	volume = {2},
	issn = {2471-285X},
	doi = {10.1109/TETCI.2017.2783885},
	abstract = {Programming sound synthesizers is a complex and time-consuming task. Automatic synthesizer programming involves finding parameters for sound synthesizers using algorithmic methods. Sound matching is one application of automatic programming, where the aim is to find the parameters for a synthesizer that cause it to emit as close a sound as possible to a target sound. We describe and compare several sound matching techniques that can be used to automatically program the Dexed synthesizer, which is a virtual model of a Yamaha DX7. The techniques are a hill climber, a genetic algorithm, and three deep neural networks that have not been applied to the problem before. We define a sound matching task based on six sets of sounds, which we derived from increasingly complex configurations of the Dexed synthesis algorithm. A bidirectional, long short-term memory network with highway layers performed better than any other technique and was able to match sounds closely in 25\% of the test cases. This network was also able to match sounds in near real time, once trained, which provides a significant speed advantage over previously reported techniques that are based on search heuristics. We also describe our open source framework, which makes it possible to repeat our study, and to adapt it to different synthesizers and algorithmic programming techniques.},
	number = {2},
	journal = {IEEE Transactions on Emerging Topics in Computational Intelligence},
	author = {Yee-King, M. J. and Fedden, L. and d'Inverno, M.},
	month = apr,
	year = {2018},
	keywords = {algorithmic methods, algorithmic programming, artificial neural networks, automatic programming, automatic synthesizer programming, Computer generated music, deep networks, deep neural networks, Dexed synthesis algorithm, Dexed synthesizer, electronic music, Feature extraction, Frequency modulation, frequency modulation (FM), genetic algorithms, Genetic algorithms, genetic algorithms (GA), music, neural nets, programming, Programming profession, short-term memory network, signal synthesis, sound matching, sound matching task, Synthesizers, target sound, Task analysis, VST sound synthesizers},
	pages = {150--159}
}

@misc{noauthor_oneohtrix_2016,
	title = {Oneohtrix {Point} {Never} on the process behind his latest leap into the unknown, {Garden} of {Delete}},
	url = {https://www.musicradar.com/news/tech/oneohtrix-point-never-on-the-process-behind-his-latest-leap-into-the-unknown-garden-of-delete-633280},
	language = {EN\_GB},
	urldate = {2018-11-18},
	journal = {MusicRadar},
	month = feb,
	year = {2016},
	file = {Snapshot:/Users/bakunowski/Zotero/storage/HFVA6NH8/oneohtrix-point-never-on-the-process-behind-his-latest-leap-into-the-unknown-garden-of-delete-6.html:text/html}
}

@misc{herbert_manifesto_2011,
	title = {manifesto {\textbar} {Matthew} {Herbert}},
	url = {https://matthewherbert.com/about-contact/manifesto/},
	language = {en-US},
	urldate = {2018-11-18},
	author = {Herbert, Matthew},
	year = {2011},
	file = {Snapshot:/Users/bakunowski/Zotero/storage/WFUG5ZYL/manifesto.html:text/html}
}

@misc{mcdonald_neural_2017,
	title = {Neural {Nets} for {Generating} {Music}},
	url = {https://medium.com/artists-and-machine-intelligence/neural-nets-for-generating-music-f46dffac21c0},
	abstract = {Algorithmic music composition has developed a lot in the last few years, but the idea has a long history. In some sense, the first…},
	urldate = {2018-11-18},
	journal = {Artists and Machine Intelligence},
	author = {McDonald, Kyle},
	month = aug,
	year = {2017},
	file = {Snapshot:/Users/bakunowski/Zotero/storage/GPC275VZ/neural-nets-for-generating-music-f46dffac21c0.html:text/html}
}

@article{tatar_automatic_2016,
	title = {Automatic {Synthesizer} {Preset} {Generation} with \textit{{PresetGen}}},
	volume = {45},
	issn = {0929-8215, 1744-5027},
	url = {http://www.tandfonline.com/doi/full/10.1080/09298215.2016.1175481},
	doi = {10.1080/09298215.2016.1175481},
	abstract = {We refer the task of ﬁnding preset(s) (i.e. set(s) of synthesizer parameters) that approximates a target sound best, as the preset generation problem. PresetGen addresses this problem regarding the real world synthesizer, OP-1. The OP-1 consists of several synthesis blocks, and it is not fully deterministic. We propose and evaluate a solution to preset generation using a multi-objective Non-dominated Sorting-Genetic-AlgorithmII. PresetGen handles the full problem complexity and returns a small set of presets that approximate the target sound best by covering the Pareto front of this multi-objective optimization problem. Moreover, we present an empirical evaluation experiment that compares the performance of three human sound designers to that of PresetGen. The results show that PresetGen is human-competitive.},
	language = {en},
	number = {2},
	urldate = {2018-11-19},
	journal = {Journal of New Music Research},
	author = {Tatar, Kıvanç and Macret, Matthieu and Pasquier, Philippe},
	month = apr,
	year = {2016},
	pages = {124--144},
	file = {Tatar et al. - 2016 - Automatic Synthesizer Preset Generation with iPr.pdf:/Users/bakunowski/Zotero/storage/FMM8VVVT/Tatar et al. - 2016 - Automatic Synthesizer Preset Generation with iPr.pdf:application/pdf}
}

@misc{noauthor_granulator_nodate,
	title = {Granulator by {Robert} {Henke}},
	url = {http://roberthenke.com/technology/granulator.html},
	urldate = {2018-11-19},
	file = {Granulator by Robert Henke:/Users/bakunowski/Zotero/storage/AZDJXF8F/granulator.html:text/html}
}

@article{gerhard_pitch_nodate,
	title = {Pitch {Extraction} and {Fundamental} {Frequency}: {History} and {Current} {Techniques}},
	abstract = {Pitch extraction (also called fundamental frequency estimation) has been a popular topic in many ﬁelds of research since the age of computers. Yet in the course of some 50 years of study, current techniques are still not to a desired level of accuracy and robustness. When presented with a single clean pitched signal, most techniques do well, but when the signal is noisy, or when there are multiple pitch streams, many current pitch algorithms still fail to perform well. This report presents a discussion of the history of pitch detection techniques, as well as a survey of the current state of the art in pitch detection technology.},
	language = {en},
	author = {Gerhard, David},
	pages = {23},
	file = {Gerhard - Pitch Extraction and Fundamental Frequency Histor.pdf:/Users/bakunowski/Zotero/storage/PSTJTR6N/Gerhard - Pitch Extraction and Fundamental Frequency Histor.pdf:application/pdf}
}

@book{muller_information_2007,
	title = {Information {Retrieval} for {Music} and {Motion}},
	isbn = {978-3-540-74048-3},
	abstract = {A general scenario that has attracted a lot of attention for multimedia information retrieval is based on the query-by-example paradigm: retrieve all documents from a database containing parts or aspects similar to a given data fragment. However, multimedia objects, even though they are similar from a structural or semantic viewpoint, often reveal significant spatial or temporal differences. This makes content-based multimedia retrieval a challenging research field with many unsolved problems.  Meinard Müller details concepts and algorithms for robust and efficient information retrieval by means of two different types of multimedia data: waveform-based music data and human motion data. In Part I, he discusses in depth several approaches in music information retrieval, in particular general strategies as well as efficient algorithms for music synchronization, audio matching, and audio structure analysis. He also shows how the analysis results can be used in an advanced audio player to facilitate additional retrieval and browsing functionality. In Part II, he introduces a general and unified framework for motion analysis, retrieval, and classification, highlighting the design of suitable features, the notion of similarity used to compare data streams, and data organization. The detailed chapters at the beginning of each part give consideration to the interdisciplinary character of this field, covering information science, digital signal processing, audio engineering, musicology, and computer graphics.   This first monograph specializing in music and motion retrieval appeals to a wide audience, from students at the graduate level and lecturers to scientists working in the above mentioned fields in academia or industry. Lecturers and students will benefit from the didactic style, and each unit is suitable for stand-alone use in specialized graduate courses. Researchers will be interested in the detailed description of original research results and their application in real-world browsing and retrieval scenarios.},
	language = {en},
	publisher = {Springer Science \& Business Media},
	author = {Müller, Meinard},
	month = sep,
	year = {2007},
	note = {Google-Books-ID: kSzeZWR2yDsC},
	keywords = {Computers / Computer Science, Computers / Interactive \& Multimedia, Computers / Computer Graphics, Computers / Data Processing, Computers / Databases / General, Computers / Desktop Applications / Design \& Graphics, Computers / General, Computers / Information Technology, Computers / System Administration / Storage \& Retrieval}
}