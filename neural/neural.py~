import pandas as pd
import numpy as np
import matplotlib.pyplot as plt
import seaborn as sns
from sklearn.preprocessing import MinMaxScaler
import tensorflow as tf

test_array = []
mfcc = pd.read_json('MFCC.json')
mfcc_np = np.asarray(mfcc)

c = np.array(list(mfcc_np[:,0]))

parameters = pd.read_json('parameters.json', orient='index')

duration = pd.read_json((parameters['duration']).to_json())
duration_np = np.array(duration)

number_of_grains = pd.read_json((parameters['numberOfGrains']).to_json())
number_of_grains_np = np.array(number_of_grains)

pitch = pd.read_json((parameters['pitch']).to_json())
pitch_np = np.array(pitch)

position = pd.read_json((parameters['position']).to_json())
position_np = np.array(position)

spread = pd.read_json((parameters['spread']).to_json())
spread_np = np.array(spread)

test = np.reshape(duration_np, (6299, 1))
test2 = np.reshape(number_of_grains_np, (6299, 1))
test3 = np.reshape(pitch_np, (6299, 1))
test4 = np.reshape(position_np, (6299, 1))
test5 = np.reshape(spread_np, (6299, 1))

# X_train = mfcc_np
X_train = c[0:6000]
X_test = c[6000:6299]
a = np.concatenate((test, test2, test3, test4, test5), axis=1)
y_train = a[0:6000]
y_test = a[6000:6299]

print("Train dimensions", X_train.shape)
print("Train labels dimensions", y_train.shape)

# set learning variables
learning_rate = 0.05
epochs = 50
batch_size = 3

# set some variables
x = tf.placeholder(tf.float32, [None, 13], name='x')  # 1 feature
y = tf.placeholder(tf.float32, [None, 5], name='y')  # 5 outputs

# hidden layer 1
W1 = tf.Variable(tf.truncated_normal([13, 10], stddev=0.03), name='W1')
b1 = tf.Variable(tf.truncated_normal([10]), name='b1')

# hidden layer 2
W2 = tf.Variable(tf.truncated_normal([10, 5], stddev=0.03), name='W2')
b2 = tf.Variable(tf.truncated_normal([5]), name='b2')

# Activations, outputs
# output hidden layer 1
hidden_out = tf.nn.relu(tf.add(tf.matmul(x, W1), b1))

# total output
y_ = tf.nn.relu(tf.add(tf.matmul(hidden_out, W2), b2))

# Loss Function
mse = tf.losses.mean_squared_error(y, y_)
mae = tf.metrics.mean_absolute_error(y, y_)
# Optimizer
optimizer = tf.train.GradientDescentOptimizer(
    learning_rate=learning_rate).minimize(mse)

# Initialize, Accuracy and Run
# initialize variables
init_op = tf.global_variables_initializer()

# accuracy for the test set
accuracy = tf.reduce_mean(tf.square(tf.subtract(
    y, y_)))  # or could use tf.losses.mean_squared_error

# run
with tf.Session() as sess:
    sess.run(init_op)
    total_batch = int(len(y_train) / batch_size)
    for epoch in range(epochs):
        avg_cost = 0
        for i in range(total_batch):
            batch_x, batch_y = X_train[i * batch_size:min(i * batch_size + batch_size,len(X_train)),:],\
                               y_train[i * batch_size:min(i * batch_size + batch_size, len(y_train)), :]
            _, c = sess.run([optimizer, mse],feed_dict={x: batch_x,y: batch_y})
            avg_cost += c / total_batch
        if epoch % 10 == 0:
            print('Epoch:', (epoch+1), 'cost =', '{:.3f}'.format(avg_cost), 'mae = ', '{:.3f}'.format(mae))
    print(sess.run(mse, feed_dict={x: X_test, y: y_test}))
