import json
import numpy as np
import tensorflow as tf
from tensorflow.keras import layers
import pandas as pd

print(tf.VERSION)
print(tf.keras.__version__)

with open(
        '/Users/bakunowski/Documents/goldsmiths/2018_19/dissertation/project/neural/test.json'
) as f:
    json_data = json.load(f)

mfcc = np.array(json_data["mfcc"])

with open(
        '/Users/bakunowski/Documents/goldsmiths/2018_19/dissertation/project/neural/parameters.json'
) as f:
    d2 = json.load(f)

duration = np.array(d2["parameters"]["duration"]).reshape(6299, 1)
numberOfGrains = np.array(d2["parameters"]["numberOfGrains"]).reshape(6299, 1)
pitch = np.array(d2["parameters"]["pitch"]).reshape(6299, 1)
position = np.array(d2["parameters"]["position"]).reshape(6299, 1)
spread = np.array(d2["parameters"]["spread"]).reshape(6299, 1)

parameters = np.concatenate(
    (duration, numberOfGrains, pitch, position, spread), axis=1)

mfcc_shuffled = np.random.shuffle(mfcc)
parameters_shuffled = np.random.shuffle(parameters)
numberOfGrains_shuffled = np.random.shuffle(numberOfGrains)

np.random.shuffle(mfcc)
np.random.shuffle(numberOfGrains)

X_train = mfcc[0:5000]
# y_train = parameters
y_train = numberOfGrains[0:5000]

X_test = mfcc[5001:6299]
y_test = numberOfGrains[5001:6299]

print(mfcc[0][0])
print("Train dimensions", X_train.shape)
print("Train labels dimensions", y_train.shape)


def norm(x):
    return (x - np.mean(x)) / np.std(x)


def build_model():
    model = tf.keras.Sequential([
        # add a densly-connected layer with 64 units to the model:
        layers.Dense(500, activation=tf.nn.relu,
                     input_shape=[len(X_train[1])]),
        # add another
        layers.Dense(500, activation=tf.nn.relu),
        # no activation function here, because regression
        # 5 as in number of outputs we'd like to have
        layers.Dense(1)
    ])

    optimizer = tf.keras.optimizers.RMSprop(0.005)

    model.compile(optimizer=optimizer,
                  loss='mean_squared_error',
                  metrics=['mean_absolute_error', 'mean_squared_error'])

    return model


model = build_model()

# model.summary()

# example_batch = norm(X_train[:10])
# example_result = model.predict(example_batch)
# print(example_result)

early_stop = tf.keras.callbacks.EarlyStopping(monitor='val_loss', patience=10)

EPOCHS = 1000

# history = model.fit(norm(X_train),
#                     y_train,
#                     batch_size=10,
#                     epochs=EPOCHS,
#                     validation_split=0.2,
#                     verbose=1,
#                     callbacks=[early_stop])
# 
# hist = pd.DataFrame(history.history)
# hist['epoch'] = history.epoch
# hist.tail()
# 
# loss, mae, mse = model.evaluate(norm(X_test), y_test, verbose=0)
# 
# print("Testing set Mean Abs Error: {:5.2f} MPG".format(mae))
# 
# # model.fit(X_train, y_train, epochs=100, batch_size=56)
# 
# # model.evaluate(X_test, y_test, batch_size=32)
# 
# # output of the last layer for new data
# test_pred = model.predict(norm(X_test))
# print(test_pred, y_test)
