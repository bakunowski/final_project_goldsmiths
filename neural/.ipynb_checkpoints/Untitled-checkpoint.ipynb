{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.13.1\n",
      "2.2.4-tf\n",
      "1.13.1\n",
      "2.2.4-tf\n",
      "(860, 45, 13)\n",
      "(860, 1)\n",
      "Train dimensions (430, 45, 13)\n",
      "Train labels dimensions (430, 5)\n",
      "Train dimensions (430, 45, 13)\n",
      "Train labels dimensions (430, 5)\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras import layers\n",
    "import pandas as pd\n",
    "import keras\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Dropout, Flatten, Conv2D, MaxPooling2D\n",
    "from keras.utils import to_categorical\n",
    "import os\n",
    "import sys\n",
    "import tflearn\n",
    "import numpy as np\n",
    "from tqdm import tqdm\n",
    "\n",
    "\n",
    "print(tf.VERSION)\n",
    "print(tf.keras.__version__)\n",
    "\n",
    "import json\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras import layers\n",
    "import pandas as pd\n",
    "import keras\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Dropout, Flatten, Conv2D, MaxPooling2D\n",
    "from keras.utils import to_categorical\n",
    "import os\n",
    "import sys\n",
    "import tflearn\n",
    "import numpy as np\n",
    "from tqdm import tqdm\n",
    "\n",
    "\n",
    "print(tf.VERSION)\n",
    "print(tf.keras.__version__)\n",
    "\n",
    "with open(\n",
    "        '/Users/bakunowski/Documents/goldsmiths/2018_19/dissertation/project/neural/MFCC_new.json'\n",
    ") as f:\n",
    "    d2 = json.load(f)\n",
    "\n",
    "# mfcc = np.array(d2[\"lowlevel\"][\"mfcc\"])[0:36000].reshape(800, 45, 13)\n",
    "# test = np.array(d2[\"lowlevel\"][\"mfcc\"])\n",
    "\n",
    "mfcc = np.array(d2[\"lowlevel\"][\"mfcc\"])[0:38700].reshape(860, 45, 13)\n",
    "\n",
    "\n",
    "with open(\n",
    "        '/Users/bakunowski/Documents/goldsmiths/2018_19/dissertation/project/neural/parameters_new.json'\n",
    ") as f:\n",
    "    d1 = json.load(f)\n",
    "\n",
    "duration = np.array(d1[\"parameters\"][\"duration\"])[0:860].reshape(860, 1)\n",
    "numberOfGrains = np.array(d1[\"parameters\"][\"numberOfGrains\"])[0:860].reshape(860, 1)\n",
    "pitch = np.array(d1[\"parameters\"][\"pitch\"])[0:860].reshape(860, 1)\n",
    "position = np.array(d1[\"parameters\"][\"position\"])[0:860].reshape(860, 1)\n",
    "spread = np.array(d1[\"parameters\"][\"spread\"])[0:860].reshape(860, 1)\n",
    "\n",
    "parameters = np.concatenate(\n",
    "    (duration, numberOfGrains, pitch, position, spread), axis=1)\n",
    "\n",
    "# print(test.shape)\n",
    "print(mfcc.shape)\n",
    "\n",
    "# print(test.shape)\n",
    "print(numberOfGrains.shape)\n",
    "\n",
    "X_train = mfcc[:430].reshape(430, 45, 13)\n",
    "y_train = parameters[:430]\n",
    "\n",
    "X_test = mfcc[430:860].reshape(430, 45, 13)\n",
    "y_test = parameters[430:860]\n",
    "\n",
    "np.set_printoptions(suppress=True)\n",
    "print(\"Train dimensions\", X_train.shape)\n",
    "print(\"Train labels dimensions\", y_train.shape)\n",
    "print(\"Train dimensions\", X_test.shape)\n",
    "print(\"Train labels dimensions\", y_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "45\n",
      "13\n",
      "5\n"
     ]
    }
   ],
   "source": [
    "print(X_train[0].shape[0])\n",
    "print(X_train[0].shape[1])\n",
    "print(y_train[0].shape[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "learning_rate = 0.001\n",
    "training_iters = 40\n",
    "batch_size = 64\n",
    "number_hidden = 256\n",
    "parameter_size = y_train[0].shape[0]\n",
    "features_cols = X_train[0].shape[0]\n",
    "features_rows = X_train[0].shape[1]\n",
    "\n",
    "net = tflearn.input_data([None, 13, 45])\n",
    "net = tflearn.lstm(net, number_hidden, dropout=0.8)\n",
    "net = tflearn.fully_connected(net, parameter_size, activation='relu')\n",
    "net = tflearn.regression(net, optimizer='adam', learning_rate=learning_rate,\n",
    "                         loss='mean_square')\n",
    "model = tflearn.DNN(net, tensorboard_verbose=3)\n",
    "\n",
    "# model.fit(X_train, y_train, batch_size=batch_size, n_epoch=training_iters)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.fit(X_test, y_test, batch_size=batch_size, n_epoch=training_iters)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
